# Malware Detection using V-gram
#
# Kim Sunwoong (2017029425, sunung007@hanyang.ac.kr)
# Kim Sungae (2018007983, abc4571998@hanyang.ac.kr)
#
# This project is conducted
# in 'CSE Capstone' class(Prof. Lim Eulgyu),
# Hanyang university.


##########
# Import #
##########
import os
import sys
import argparse

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from util.Fvector import Fvector

###############
# Import Util #
###############
sys.path.insert(0, "./../")
from util import *


def _compare_fvlen(df: pd.DataFrame, model_type: str, candidates: list):
    fvector = Fvector()
    y_all = dataset["isMalware"].values.reshape(-1, 1)

    result = []
    for i in tqdm(range(len(candidates))):
        fvector_len = candidates[i]

        # make feature vector
        feature_vector = fvector.feature_hashing(
            df["basic_blocks_hashed"].tolist(), fvector_len
        )

        # feature vector 생성
        hasher = FeatureHasher(n_features=fvector_len)
        feature_vector = hasher.transform(
            [dict(Counter(f)) for f in dataset["basic_blocks_hashed"].tolist()]
        ).toarray()

        # dataset
        x_train, x_test, y_train, y_test = train_test_split(
            feature_vector,
            y_all,
            test_size=0.2,
            random_state=123,
            shuffle=True,
            stratify=y_all,
        )

        if model_type == "dnn":
            dnn_input_shape = (fvector_len,)
            dnn_model = Model("dnn", make_model_dnn)
            dnn_model.fit(
                input_shape=dnn_input_shape,
                x_train=x_train.reshape((len(x_train),) + dnn_input_shape),
                x_test=x_test.reshape((len(x_test),) + dnn_input_shape),
                y_train=y_train,
                y_test=y_test,
                epochs=50,
                use_fold=True,
                fold_num=5,
                fold_epochs=50,
                batch_size=512,
            )
            evaluate = dnn_model.evaluate(x_test, y_test)

        elif model_type == "cnn":
            cnn_input_shape = (fvector_len, 1)
            cnn_model = Model("cnn", make_model_cnn)
            cnn_model.fit(
                input_shape=cnn_input_shape,
                x_train=x_train.reshape((len(x_train),) + cnn_input_shape),
                x_test=x_test.reshape((len(x_test),) + cnn_input_shape),
                y_train=y_train,
                y_test=y_test,
                epochs=50,
                use_fold=True,
                fold_num=5,
                fold_epochs=50,
                batch_size=512,
            )
            evaluate = cnn_model.evaluate(x_test, y_test)

        elif model_type == "rf":
            y_train = y_train.flatten()
            y_test = y_test.flatten()

            rf_model = RandomForestClassifier(n_estimators=120)
            rf_model.fit(x_train, y_train)

            evaluate = [
                0,
                f1_score(y_test, rf_model.predict(x_test)),
                rf_model.score(x_test, y_test),
            ]

        else:
            print("Invalid model name", file=sys.stderr)
            raise ValueError

        result.append(evaluate)

        print(
            f"""
length of feature vector: {fvector_len}
    - loss: {evaluate[0]}
    - f1-score: {evaluate[1]}
    - accuracy: {evaluate[2]}
"""
        )

    result = np.array(result, dtype=np.float64)

    # 결과 그래프 확인
    print("|".join(map(str, candidates)) + "|")
    print(
        "|".join(
            [
                (str(round(i, 4)) + ("0" * (6 - len(str(round(i, 4))))))
                for i in result[:, 0].tolist()
            ]
        )
        + "|"
    )  # loss
    print(
        "|".join(
            [
                (str(round(i, 4)) + ("0" * (6 - len(str(round(i, 4))))))
                for i in result[:, 2].tolist()
            ]
        )
        + "|"
    )  # accuracy
    print(
        "|".join(
            [
                (str(round(i, 4)) + ("0" * (6 - len(str(round(i, 4))))))
                for i in result[:, 1].tolist()
            ]
        )
        + "|"
    )  # f1

    # print("\t".join([(str(round(i, 4)) + ("0" * (6-len(str(round(i, 4)))))) for i in result[:, 0].tolist()]))
    # print("\t".join([(str(round(i, 4)) + ("0" * (6-len(str(round(i, 4)))))) for i in result[:, 2].tolist()]))
    # print("\t".join([(str(round(i, 4)) + ("0" * (6-len(str(round(i, 4)))))) for i in result[:, 1].tolist()]))

    plt.figure(figsize=(40, 9))
    plt.subplot(1, 3, 1)
    plt.plot(range(len(candidates)), result[:, 0], label="loss")
    plt.xticks(range(len(candidates)), list(map(str, candidates)))
    plt.xlabel("Change of Loss")
    plt.grid()
    plt.legend()

    plt.subplot(1, 3, 2)
    plt.plot(range(len(candidates)), result[:, 1], label="f1 score")
    plt.xticks(range(len(candidates)), list(map(str, candidates)))
    plt.xlabel("Change of F1 score")
    plt.grid()
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(range(len(candidates)), result[:, 2], label="accuracy")
    plt.xticks(range(len(candidates)), list(map(str, candidates)))
    plt.xlabel("Change of Accuracy")
    plt.grid()
    plt.legend()
    plt.show()


if __name__ == "__main__":
    # Arguments : setting
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--fvlen",
        type=int,
        default=4098,
        help="length of feature vector (Default: 4098).",
    )
    parser.add_argument(
        "--compare_fvlen",
        type=lambda s: s == "True",
        required=True,
        help="wether compare result according to feature vector length. Valid value is True or False",
    )
    parser.add_argument(
        "--model",
        type=str,
        default="all",
        help="model to use. Select from 'dnn', 'cnn', 'rf' or 'all'. Default is 'all'.",
    )

    ###########################################

    # Arguments : get
    args = parser.parse_args()

    fvlen = args.fvlen
    compare_fvlen = args.compare_fvlen
    model_name = args.model

    dnn_input_shape = (fvlen,)
    cnn_input_shape = (fvlen, 1)

    feature_cols = [f"feature_vector_{i}" for i in range(1, fvlen + 1)]

    ###########################################

    # read/download dataset
    if not os.path.isdir(f"{MAIN_DIR}/data/total_data"):
        dataset = download_and_read_dataset()
    else:
        dataset = pd.concat(
            [
                read_opcodes(f"{MAIN_DIR}/data/total_data/0", False),
                read_opcodes(f"{MAIN_DIR}/data/total_data/1", True),
            ]
        ).reset_index(drop=True)

    print("총 데이터셋 수 :", len(dataset))

    ###########################################

    # make dataset
    fvector = Fvector()
    dataset = fvector.fit(dataset, fvlen, "isMalware", "opcodes").reset_index(drop=True)
    print("전처리 된 데이터셋 수 :", len(dataset))

    if compare_fvlen:
        fvector_len_cands = [
            32,
            64,
            128,
            256,
            512,
            1024,
            2048,
            4096,
            4096 * 2,
            4096 * 4,
            4096 * 8,
        ]
        _compare_fvlen(dataset, "dnn", fvector_len_cands)
        _compare_fvlen(dataset, "cnn", fvector_len_cands)
        _compare_fvlen(dataset, "rf", fvector_len_cands)

    else:
        x_all = dataset[feature_cols].values
        y_all = dataset["isMalware"].values.reshape(-1, 1)
        x_train, x_test, y_train, y_test = train_test_split(
            x_all, y_all, test_size=0.2, random_state=123, stratify=y_all
        )

        if model_name == "dnn" or model_name == "all":
            dnn_model = Model("dnn", make_model_dnn)
            dnn_history = dnn_model.fit(
                input_shape=dnn_input_shape,
                x_train=x_train.reshape((len(x_train),) + dnn_input_shape),
                x_test=x_test.reshape((len(x_test),) + dnn_input_shape),
                y_train=y_train,
                y_test=y_test,
                epochs=50,
                use_fold=True,
                fold_num=5,
                fold_epochs=50,
                batch_size=512,
            )

        if model_name == "cnn" or model_name == "all":
            cnn_model = Model("cnn", make_model_cnn)
            cnn_history = cnn_model.fit(
                input_shape=cnn_input_shape,
                x_train=x_train.reshape((len(x_train),) + cnn_input_shape),
                x_test=x_test.reshape((len(x_test),) + cnn_input_shape),
                y_train=y_train,
                y_test=y_test,
                epochs=50,
                use_fold=True,
                fold_num=5,
                fold_epochs=50,
                batch_size=512,
            )

        if model_name == "rf" or model_name == "all":
            rf_model = RandomForestClassifier(n_estimators=120)
            rf_model.fit(x_train, y_train.flatten())

            predict = rf_model.predict(x_test)
            joblib.dump(rf_model, "random_forest.joblib", compress=3)
