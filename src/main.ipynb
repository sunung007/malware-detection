{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, \".\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hashlib import sha256\n",
    "from collections import Counter\n",
    "\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Input, Conv1D, MaxPooling1D, Dropout, Flatten, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.regularizers import L2\n",
    "from keras import backend as K\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import jaccard_score, f1_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction import FeatureHasher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vector 수\n",
    "FEATURE_VECTOR_LEN = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # read/download dataset\n",
    "# if not os.path.isdir(f\"{MAIN_DIR}/data/total_data\"):\n",
    "#     dataset = download_and_read_dataset()\n",
    "# else:\n",
    "#     dataset = pd.concat(\n",
    "#         [\n",
    "#             read_opcodes(f\"{MAIN_DIR}/data/total_data/0\", False),\n",
    "#             read_opcodes(f\"{MAIN_DIR}/data/total_data/1\", True),\n",
    "#         ]\n",
    "#     ).reset_index(drop=True)\n",
    "\n",
    "# print(\"총 데이터셋 수 :\", len(dataset))\n",
    "\n",
    "# # make dataset\n",
    "# fvector = Fvector()\n",
    "# dataset = fvector.fit(dataset, FEATURE_VECTOR_LEN, 'isMalware', 'opcodes').reset_index(drop=True)\n",
    "# print(\"전처리 된 데이터셋 수 :\", len(dataset))\n",
    "\n",
    "# # feature vector만 추출\n",
    "# fdataset = dataset.drop(\n",
    "#     ['opcodes', 'basic_blocks', 'basic_blocks_num', 'basic_blocks_hashed'], \n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# # 데이터셋 구성\n",
    "# feature_cols = [f\"feature_vector_{i}\" for i in range(1, FEATURE_VECTOR_LEN+1)]\n",
    "\n",
    "# x_all = fdataset[feature_cols].values\n",
    "# y_all = fdataset['isMalware'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using utilized code\n",
    "# fold_num = 5\n",
    "# models = Model(x_all=x_all, y_all=y_all)\n",
    "\n",
    "# input_shape = (FEATURE_VECTOR_LEN, )\n",
    "# models.dnn_train(input_shape)\n",
    "\n",
    "# input_shape = (FEATURE_VECTOR_LEN, 1)\n",
    "# models.cnn_train(input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all files\n",
    "result = []\n",
    "for fname in os.listdir(f\"{MAIN_DIR}/data/total_data/0\"): # 정상 파일\n",
    "    with open(f\"{MAIN_DIR}/data/total_data/0/{fname}\") as file:\n",
    "        result.append([fname[:-8], [i.strip().lower() for i in file.readlines()], 0])\n",
    "\n",
    "for fname in os.listdir(f\"{MAIN_DIR}/data/total_data/1\"): # 악성 파일\n",
    "    with open(f\"{MAIN_DIR}/data/total_data/1/{fname}\") as file:\n",
    "        result.append([fname[:-8], [i.strip().lower() for i in file.readlines()], 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(result, columns=['name', 'opcodes', 'isMalware'])\n",
    "# 앞에 3글자만 사용\n",
    "# dataset['opcodes'] = dataset['opcodes'].apply(lambda opcodes: [word[:3] for word in opcodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_normal = len(dataset[dataset['isMalware'] == 0])\n",
    "# num_malware = len(dataset[dataset['isMalware'] == 1])\n",
    "\n",
    "# print(f\"정상 : {num_normal}개 / 악성 : {num_malware}개\")\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.bar(['normal', 'malware'], [num_normal, num_malware])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = Counter([j for i in dataset['opcodes'].tolist() for j in i])\n",
    "# counter_values = np.array(list(counter.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 가장 많이 나타나는 opcode 상위 20개\n",
    "# plt.figure(figsize=(20, 9))\n",
    "# plt.bar(list(map(lambda l: l[0], counter.most_common(20))), list(map(lambda l: l[1], counter.most_common(20))))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "# f\"\"\"\n",
    "# 총합 : {counter_values.sum()}\n",
    "# 평균 : {counter_values.mean()}\n",
    "# 최소 : {counter_values.min()}\n",
    "# 최대 : {counter_values.max()}\n",
    "# -----------------------------\n",
    "# 전체 opcode 수 : {len(counter_values)}\n",
    "# 2회 이상 opcode 수 : {(counter_values > 1).sum()}\n",
    "# 3회 이상 opcode 수 : {(counter_values > 2).sum()}\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Block 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperator : jump instructions + return instructions\n",
    "jmp_inst = [\n",
    "    'jmp', 'jz', 'jnz', 'jb', 'jnb', 'jl', 'jle', 'jg', \n",
    "    'ja', 'jbe', 'jge', 'jno', 'jns', 'js', 'jp', 'jnp', \n",
    "    'jo', 'jecxz', 'jcxz'\n",
    "]\n",
    "ret_inst = ['retnw', 'retfw', 'retf', 'retfw', 'retn', 'retnw']\n",
    "\n",
    "seperator = jmp_inst + ret_inst\n",
    "\n",
    "len(jmp_inst), len(ret_inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_basic_block(\n",
    "    commands: list, min_opcode: int = 10, min_basic_block: int = 100\n",
    ") -> list:\n",
    "    cur = []\n",
    "    basic_blocks = []\n",
    "\n",
    "    for com in commands:\n",
    "        cur.append(com)\n",
    "        if com in seperator:\n",
    "            if len(cur) > min_opcode: # opcode 수가 적은 block은 버림\n",
    "                basic_blocks.append(cur)\n",
    "            cur = []\n",
    "    basic_blocks.append(cur)\n",
    "\n",
    "    return [] if len(basic_blocks) < min_basic_block else basic_blocks # block 수가 적은 파일은 버림"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic block 생성\n",
    "dataset['basic_blocks'] = dataset['opcodes'].apply(lambda l: split_to_basic_block(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic block 개수\n",
    "dataset['basic_blocks_num'] = dataset['basic_blocks'].apply(lambda l: len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic block이 적은 데이터들은 버림\n",
    "dataset.drop(dataset[dataset[\"basic_blocks_num\"] == 0].index, inplace=True)\n",
    "dataset.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dataset[dataset['isMalware'] == 0]['basic_blocks_num'].describe(),\n",
    "    \"---------------------------------------\",\n",
    "    dataset[dataset['isMalware'] == 1]['basic_blocks_num'].describe()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20, 9))\n",
    "\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.hist(dataset[dataset['isMalware'] == 0]['basic_blocks_num'], range=(0, 10000), bins=50)\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.hist(dataset[dataset['isMalware'] == 1]['basic_blocks_num'], range=(0, 10000), bins=50)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 basic block을 하나의 string으로 연결\n",
    "dataset['basic_blocks_str'] = dataset['basic_blocks'].apply(\n",
    "    lambda blocks: [\"\".join(block) for block in blocks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 basic block을 hashing\n",
    "dataset['basic_blocks_hashed'] = dataset['basic_blocks_str'].apply(\n",
    "    lambda blocks: [sha256(block.encode()).hexdigest() for block in blocks]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Vector 생성\n",
    "Class로 대체 완료 -> 버림"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Hashing\n",
    "Hashed basic block을 하나의 feature vector로 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv(\"./data/traindata.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vector 생성\n",
    "hasher = FeatureHasher(n_features=FEATURE_VECTOR_LEN)\n",
    "feature_vector = hasher.transform(\n",
    "    [dict(Counter(f)) for f in dataset['basic_blocks_hashed'].tolist()]\n",
    ").toarray()\n",
    "\n",
    "# dataframe에 삽입\n",
    "dataset = pd.concat(\n",
    "    [\n",
    "        dataset,\n",
    "        pd.DataFrame(feature_vector, columns=[f\"feature_vector_{i}\" for i in range(1, FEATURE_VECTOR_LEN+1)])\n",
    "    ],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature vector만 추출해서 저장\n",
    "fdataset = dataset.drop(\n",
    "    ['opcodes', 'basic_blocks', 'basic_blocks_num', 'basic_blocks_str', 'basic_blocks_hashed'], \n",
    "    axis=1\n",
    ")\n",
    "fdataset.to_csv(f\"{MAIN_DIR}/data/traindata_only_fvector_size={FEATURE_VECTOR_LEN}.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier (여기서부터) ⇲"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe Columns\n",
    "- name : 파일 이름\n",
    "- opcodes : 명령어 list\n",
    "- isMalware : 악성코드 여부(0: 정상파일 / 1: 악성파일)\n",
    "- basic_blocks : 파일 내 basic block 리스트\n",
    "- basic_blocks_num : 파일 내 basic block 수\n",
    "- basic_blocks_str : 각 basic block을 하나의 string으로 연결한 것\n",
    "- basic_blocks_hashed : 각 basic block을 하나의 hashed value로 만든 것\n",
    "- feature_vector_{1~10} : feature vector 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdataset = pd.read_csv(f\"{MAIN_DIR}/data/traindata_only_fvector_size={FEATURE_VECTOR_LEN}.csv\", header=0)\n",
    "fdataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상/악성 비율 맞추기\n",
    "min_cnt = min(len(fdataset[fdataset['isMalware'] == 0]), len(fdataset[fdataset['isMalware'] == 1]))\n",
    "total_dataset = fdataset.loc[\n",
    "    (\n",
    "        set(fdataset[fdataset['isMalware'] == 0].sample(min_cnt, random_state=123).index) \n",
    "        | set(fdataset[fdataset['isMalware'] == 1].sample(min_cnt, random_state=123).index)\n",
    "    )\n",
    "].sample(frac=1.0)\n",
    "\n",
    "print(\n",
    "f\"\"\"\n",
    "전체 파일 수 : {len(fdataset)}\n",
    "-------------------------------\n",
    "정상 파일 수 : {len(fdataset[fdataset['isMalware'] == 0])}\n",
    "악성 파일 수 : {len(fdataset[fdataset['isMalware'] == 1])}\n",
    "-------------------------------\n",
    "파징 후 파일 수 : {len(total_dataset)}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 구성\n",
    "feature_cols = [f\"feature_vector_{i}\" for i in range(1, FEATURE_VECTOR_LEN+1)]\n",
    "\n",
    "x_all = total_dataset[feature_cols].values\n",
    "y_all = total_dataset['isMalware'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, \n",
    "    test_size=0.2, \n",
    "    random_state=123,\n",
    "    stratify=y_all\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_f1(y_true, y_pred):\n",
    "    def recall_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        \n",
    "        recall = TP / (Positives+K.epsilon())    \n",
    "        return recall \n",
    "    \n",
    "    \n",
    "    def precision_m(y_true, y_pred):\n",
    "        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    \n",
    "        precision = TP / (Pred_Positives+K.epsilon())\n",
    "        return precision \n",
    "    \n",
    "    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)\n",
    "    \n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result(model, history, x_test, y_test):\n",
    "    loss, f1, acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "    print(\n",
    "    f\"\"\"\n",
    "    Result\n",
    "        - Loss : %3.8f\n",
    "        - F1 score : %3.8f\n",
    "        - Accuracy : %3.8f\n",
    "    \"\"\"%(loss, f1, acc))\n",
    "\n",
    "    plt.figure(figsize=(30, 9))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(len(history.history['loss'])), history.history['loss'], label='loss')\n",
    "    plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'], label='val_loss')\n",
    "    plt.axhline(loss, color='red', label='loss of testset')\n",
    "    plt.xlabel(\"Change of Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(len(history.history['custom_f1'])), history.history['custom_f1'], label='f1 score for training')\n",
    "    plt.plot(range(len(history.history['val_custom_f1'])), history.history['val_custom_f1'], label='f1 score for validation')\n",
    "    plt.axhline(f1, color='red', label='f1 score of testset')\n",
    "    plt.xlabel(\"Change of Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(len(history.history['binary_accuracy'])), history.history['binary_accuracy'], label='accuracy for training')\n",
    "    plt.plot(range(len(history.history['val_binary_accuracy'])), history.history['val_binary_accuracy'], label='accuracy for validation')\n",
    "    plt.axhline(acc, color='red', label='accuracy of testset')\n",
    "    plt.xlabel(\"Change of Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    name:str, make_model, input_shape,\n",
    "    x_train, x_test, y_train, y_test,\n",
    "    epochs:int = 100, \n",
    "    fold_num:int = 5, fold_epochs:int = 100,\n",
    "    batch_size:int = None\n",
    "):\n",
    "    print(\n",
    "    f\"\"\"\n",
    "    Shape of input data\n",
    "        - train : {x_train.shape}\n",
    "        - test : {x_test.shape}\n",
    "        ------------------------\n",
    "        - input shape : {input_shape}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "    fold_num = min(fold_num, len(x_train)) if len(x_train) < 10000 else 0\n",
    "\n",
    "    ##########\n",
    "    # K-fold #\n",
    "    ##########\n",
    "\n",
    "    if fold_num > 0:\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            f\"{MAIN_DIR}/model/{name}.kfold.model\",\n",
    "            monitor='custom_f1',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "        \n",
    "        kfold = StratifiedKFold(n_splits=fold_num, shuffle=True)\n",
    "        kfold_models = []\n",
    "        kfold_accuracy = []\n",
    "\n",
    "        for learning_iter, data in enumerate(kfold.split(x_train, y_train)):\n",
    "            ############\n",
    "            # training #\n",
    "            ############\n",
    "\n",
    "            train_index, valid_index = data\n",
    "            x_train_fold = x_train[train_index]\n",
    "            y_train_fold = y_train[train_index]\n",
    "            x_test_fold = x_train[valid_index]\n",
    "            y_test_fold = y_train[valid_index]\n",
    "\n",
    "            # 모델 구성 & 훈련\n",
    "            model = make_model(\n",
    "                input_shape=input_shape, \n",
    "                use_batch=(batch_size is not None)\n",
    "            )\n",
    "            history = model.fit(\n",
    "                x_train_fold, y_train_fold,\n",
    "                epochs=fold_epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_split=0.2,\n",
    "                verbose=0,\n",
    "                callbacks=[checkpoint]\n",
    "            )\n",
    "            model = load_model(\n",
    "                f\"{MAIN_DIR}/model/{name}.kfold.model\", \n",
    "                custom_objects={\"custom_f1\": custom_f1}\n",
    "            )\n",
    "            kfold_models.append(model)\n",
    "\n",
    "            ##########\n",
    "            # result #\n",
    "            ##########\n",
    "            evaluate = model.evaluate(x_test_fold, y_test_fold)\n",
    "            # train f1 score, train accuracy, \n",
    "            # test loss, test f1 score, test accuracy\n",
    "            kfold_accuracy.append(evaluate)\n",
    "        \n",
    "            print(f\"\"\"\n",
    "        Learning Iteration : %d\n",
    "            - Loss of test fold\\t %.8f\n",
    "            - F1 score of test fold\\t %3.8f\n",
    "            - Accuracy of test fold\\t %3.8f\n",
    "        \"\"\" % (learning_iter + 1, evaluate[0], evaluate[1], evaluate[2]))\n",
    "\n",
    "            predict = model.predict(x_test_fold)\n",
    "            test_result = [(y_test_fold.flatten() > 0.5).sum(), len(x_test_fold)]\n",
    "            test_result[1] -= test_result[0]\n",
    "            predict_result = [(predict.flatten() > 0.5).sum(), len(x_test_fold)]\n",
    "            predict_result[1] -= predict_result[0]\n",
    "\n",
    "            # graph\n",
    "            plt.figure(figsize=(40, 4))\n",
    "\n",
    "            plt.subplot(1, 6, 1)\n",
    "            plt.bar([0, 1], test_result, alpha=0.5, color='red', label='real')\n",
    "            plt.bar([0, 1], predict_result, alpha=0.5, color='blue', label='predict')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 6, 2)\n",
    "            plt.bar([0, 1], test_result, alpha=0.5, color='red', label='real')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 6, 3)\n",
    "            plt.bar([0, 1], predict_result, alpha=0.5, color='blue', label='predict')\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 6, 4)\n",
    "            plt.plot(range(len(history.history['loss'])), history.history['loss'], label='loss')\n",
    "            plt.plot(range(len(history.history['val_loss'])), history.history['val_loss'], label='val_loss')\n",
    "            plt.axhline(y=evaluate[0], label='loss of test')\n",
    "            plt.xlabel(\"Change of Loss\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 6, 5)\n",
    "            plt.plot(range(len(history.history['custom_f1'])), history.history['custom_f1'], label='f1 score for train')\n",
    "            plt.plot(range(len(history.history['val_custom_f1'])), history.history['val_custom_f1'], label='f1 score for validation')\n",
    "            plt.axhline(y=evaluate[1], label='f1 score of test')\n",
    "            plt.xlabel(\"Change of F1 score\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.subplot(1, 6, 6)\n",
    "            plt.plot(range(len(history.history['binary_accuracy'])), history.history['binary_accuracy'], label='accuracy for train')\n",
    "            plt.plot(range(len(history.history['val_binary_accuracy'])), history.history['val_binary_accuracy'], label='accuracy for validation')\n",
    "            plt.axhline(y=evaluate[2], label='accuracy of test')\n",
    "            plt.xlabel(\"Change of Accuracy\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "        ###############\n",
    "        # Final train #\n",
    "        ###############\n",
    "\n",
    "        # pick best model\n",
    "        kfold_accuracy = np.array(kfold_accuracy)\n",
    "        model = kfold_models[np.argmax(kfold_accuracy[:, 1])] # f1 score 기준\n",
    "\n",
    "        # final training\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2, \n",
    "            verbose=0,\n",
    "            callbacks=[checkpoint],\n",
    "        )\n",
    "        model = load_model(\n",
    "            f\"{MAIN_DIR}/model/{name}.kfold.model\",\n",
    "            custom_objects={\"custom_f1\": custom_f1}\n",
    "        )\n",
    "\n",
    "        # 결과 확인\n",
    "        evaluate = model.evaluate(x_test, y_test)\n",
    "        print(f\"\"\"\n",
    "    K-Fold Result\n",
    "        - batch size : {batch_size}\n",
    "        - Average loss : %3.8f\n",
    "        - Average f1 score : %3.8f\n",
    "        - Average accuracy : %3.8f\n",
    "        - Final test loss : %3.8f\n",
    "        - Final test f1 score : %3.8f\n",
    "        - Final test accuracy : %3.8f\n",
    "    \"\"\" % (\n",
    "            kfold_accuracy[:, 0].mean(), \n",
    "            kfold_accuracy[:, 1].mean(),\n",
    "            kfold_accuracy[:, 2].mean(),\n",
    "            evaluate[0],\n",
    "            evaluate[1],\n",
    "            evaluate[2],\n",
    "        ))\n",
    "\n",
    "        plt.figure(figsize=(20, 9))\n",
    "        plt.plot(kfold_accuracy[:, 0], label='Loss')\n",
    "        plt.plot(kfold_accuracy[:, 1], label='F1 score')\n",
    "        plt.plot(kfold_accuracy[:, 2], label='Accuracy')\n",
    "        plt.axhline(y=kfold_accuracy[:, 0].mean(), label='Averaged loss')\n",
    "        plt.axhline(y=kfold_accuracy[:, 1].mean(), label='Averaged f1 score')\n",
    "        plt.axhline(y=kfold_accuracy[:, 2].mean(), label='Averaged accuracy')\n",
    "        plt.axhline(y=evaluate[0], label='Final loss of train')\n",
    "        plt.axhline(y=evaluate[1], label='Final f1 score of train')\n",
    "        plt.axhline(y=evaluate[2], label='Final accuracy of train')\n",
    "        plt.xlabel(\"Accuracy according to iters\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    ##############\n",
    "    # Not K-fold #\n",
    "    ##############\n",
    "    else:\n",
    "        checkpoint = ModelCheckpoint(\n",
    "            f\"{MAIN_DIR}/model/{name}.model\",\n",
    "            monitor='custom_f1',\n",
    "            verbose=0,\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "\n",
    "        # 모델 구성 & 훈련\n",
    "        model = make_model(input_shape=input_shape)\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split=0.2, \n",
    "            verbose=0,\n",
    "            callbacks=[checkpoint],\n",
    "        )\n",
    "        model = load_model(\n",
    "            f\"{MAIN_DIR}/model/{name}.model\",\n",
    "            custom_objects={\"custom_f1\": custom_f1}\n",
    "        )\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN / DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_cnn(input_shape, use_batch:bool = False):\n",
    "    model = Sequential()\n",
    "\n",
    "    conv_units = [2, 4]\n",
    "    fc_units = [4098, 256, 128, 64]\n",
    "\n",
    "    # Convolution\n",
    "    for i in range(len(conv_units)):\n",
    "        if i == 0:\n",
    "            model.add(Conv1D(3, conv_units[i], kernel_initializer='he_normal', input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Conv1D(3, conv_units[i], kernel_initializer='he_normal'))\n",
    "        if use_batch: \n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(MaxPooling1D(2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    for i in range(len(fc_units)):\n",
    "        if i == 0:\n",
    "            model.add(Dense(units=fc_units[i], kernel_initializer='he_normal', input_shape=input_shape))\n",
    "        else:\n",
    "            model.add(Dense(units=fc_units[i], kernel_initializer='he_normal'))\n",
    "        if use_batch: \n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Activation('leaky_relu'))\n",
    "\n",
    "        if i < len(fc_units) - 3:\n",
    "            model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=adam_v2.Adam(0.0001),\n",
    "        metrics=[custom_f1, 'binary_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_dnn(input_shape, use_batch=False):\n",
    "    units = [4096, 2048, 512, 128]\n",
    "\n",
    "    model = Sequential()\n",
    "    for i in range(len(units)):\n",
    "        # linear\n",
    "        if i == 0:\n",
    "            model.add(Dense(\n",
    "                units=units[i], \n",
    "                kernel_initializer='he_normal', \n",
    "                # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                # bias_regularizer=regularizers.L2(1e-4),\n",
    "                # activity_regularizer=regularizers.L2(1e-5),\n",
    "                input_shape=input_shape\n",
    "            ))\n",
    "        else:\n",
    "            model.add(Dense(\n",
    "                units=units[i], \n",
    "                kernel_initializer='he_normal',\n",
    "                # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),\n",
    "                # bias_regularizer=regularizers.L2(1e-4),\n",
    "                # activity_regularizer=regularizers.L2(1e-5)\n",
    "            ))\n",
    "        # batch normlization\n",
    "        if use_batch: \n",
    "            model.add(BatchNormalization())\n",
    "        # activation\n",
    "        model.add(Activation('leaky_relu'))\n",
    "        # dropout\n",
    "        if i < len(units) - 5:\n",
    "            model.add(Dropout(0.4))\n",
    "        elif i < len(units) - 3:\n",
    "            model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(units=1, kernel_initializer='he_normal', activation='sigmoid'))\n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=adam_v2.Adam(0.0001),\n",
    "        metrics=[custom_f1, 'binary_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_input_shape = (FEATURE_VECTOR_LEN, 1)\n",
    "cnn_model, cnn_history = train_model(\n",
    "    name=\"cnn\", make_model = make_model_cnn, input_shape = cnn_input_shape, \n",
    "    x_train = x_train.reshape((len(x_train),) + cnn_input_shape),\n",
    "    x_test = x_test.reshape((len(x_test),) + cnn_input_shape),\n",
    "    y_train = y_train, y_test = y_test,\n",
    "    epochs = 50,\n",
    "    fold_num = 5,\n",
    "    fold_epochs = 50,\n",
    "    batch_size = 512,\n",
    ")\n",
    "show_result(\n",
    "    cnn_model, cnn_history, \n",
    "    x_test = x_test.reshape((len(x_test),) + cnn_input_shape),\n",
    "    y_test = y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_input_shape = (FEATURE_VECTOR_LEN, )\n",
    "dnn_model, dnn_history = train_model(\n",
    "    name=\"dnn\", make_model = make_model_dnn, input_shape = dnn_input_shape, \n",
    "    x_train = x_train.reshape((len(x_train),) + dnn_input_shape),\n",
    "    x_test = x_test.reshape((len(x_test),) + dnn_input_shape),\n",
    "    y_train = y_train, y_test = y_test,\n",
    "    epochs = 50,\n",
    "    fold_num = 5,\n",
    "    fold_epochs = 50,\n",
    "    batch_size = 512,\n",
    ")\n",
    "show_result(\n",
    "    dnn_model, dnn_history, \n",
    "    x_test = x_test.reshape((len(x_test),) + dnn_input_shape),\n",
    "    y_test = y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "models = []\n",
    "n_cands = [120]\n",
    "\n",
    "for i in tqdm(range(len(n_cands)), desc=\"find best n\"):\n",
    "    model = RandomForestClassifier(n_estimators=n_cands[i])\n",
    "    model.fit(x_train, y_train.flatten())\n",
    "    models.append(model)\n",
    "\n",
    "    predict = model.predict(x_test)\n",
    "    result.append(model.score(x_test, y_test.flatten()))\n",
    "\n",
    "# pick best model\n",
    "rf_model = models[np.argmax(result)]\n",
    "predict = rf_model.predict(x_test)\n",
    "print(\"Best Accuracy :\", result[np.argmax(result)], f\"(n = {n_cands[np.argmax(result)]})\")\n",
    "\n",
    "plt.figure(figsize=(20, 9))\n",
    "plt.plot(n_cands, result)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(rf_model, \"random_forest.joblib\", compress=3)  # compression is ON!\n",
    "print(f\"Compressed Random Forest: {np.round(os.path.getsize('random_forest.joblib') / 1024 / 1024, 2) } MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 구성\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, \n",
    "    test_size=0.2, \n",
    "    random_state=123, \n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMClassifier()\n",
    "lgbm_model.fit(\n",
    "    x_train, y_train,\n",
    "    eval_metric='binary_logloss',\n",
    "    eval_set=[(x_test, y_test)],\n",
    "    verbose = False\n",
    ")\n",
    "predict = lgbm_model.predict(x_test)\n",
    "print(\"Accuracy : %3.8f\" % ((predict == y_test).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for max_depth in range(3, 10):\n",
    "    lgbm_model = LGBMClassifier(n_estimators=100, max_depth = max_depth)\n",
    "    lgbm_model.fit(\n",
    "        x_train, y_train,\n",
    "        eval_metric='binary_logloss',\n",
    "        eval_set=[(x_test, y_test)],\n",
    "        verbose = False\n",
    "    )\n",
    "    predict = lgbm_model.predict(x_test)\n",
    "    print(\"Accuracy : %3.8f\" % ((predict == y_test).mean()))\n",
    "    result.append((predict == y_test).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기타 실험\n",
    "이 블락 전까지만 실행하면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 구성\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_all, y_all, \n",
    "    test_size=0.2, \n",
    "    random_state=123,\n",
    "    stratify=y_all\n",
    ")\n",
    "\n",
    "dnn_predict = dnn_model.predict(x_test.reshape((len(x_test),) + dnn_input_shape))\n",
    "dnn_predict[dnn_predict >= 0.5] = 1\n",
    "dnn_predict[dnn_predict < 0.5] = 0\n",
    "\n",
    "cnn_predict = cnn_model.predict(x_test.reshape((len(x_test),) + cnn_input_shape))\n",
    "cnn_predict[cnn_predict >= 0.5] = 1\n",
    "cnn_predict[cnn_predict < 0.5] = 0\n",
    "\n",
    "rf_predict = rf_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = (dnn_predict.flatten() + cnn_predict.flatten() + rf_predict.flatten()) / 3\n",
    "predict[predict >= 0.5] = 1\n",
    "predict[predict < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Ensemble Accuracy : %3.8f\" %((predict == y_test.flatten()).mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature vector 길이에 따른 변화\n",
    "Feature Hashing 전까지는 수행해야 함.\n",
    "\n",
    "비교 결과는 README에 정리해놓음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 2\n",
    "batch_size = 512\n",
    "\n",
    "# fvector_len_cands = [32, 64, 128, 256, 512, 1024, 2048, 4096, 4096 * 2, 4096 * 4, 4096 * 8]\n",
    "fvector_len_cands = [4096 * 4, 4096 * 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(total_dataset, fvector_len):\n",
    "    total_dataset = total_dataset.copy()\n",
    "    feature_cols = [f\"feature_vector_{i}\" for i in range(1, fvector_len+1)]\n",
    "\n",
    "    x_all = total_dataset[feature_cols].values\n",
    "    y_all = total_dataset['isMalware'].values.reshape(-1, 1)\n",
    "\n",
    "    return train_test_split(\n",
    "        x_all, y_all, \n",
    "        test_size=0.2, \n",
    "        random_state=123, shuffle=True, \n",
    "        stratify=y_all\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_array(x_all, y_all):\n",
    "    return train_test_split(\n",
    "        x_all, y_all, \n",
    "        test_size=0.2, \n",
    "        random_state=123, shuffle=True, \n",
    "        stratify=y_all\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정상/악성 비율 맞추기\n",
    "min_cnt = min(len(dataset[dataset['isMalware'] == 0]), len(dataset[dataset['isMalware'] == 1]))\n",
    "dataset = dataset.loc[\n",
    "    (\n",
    "        set(dataset[dataset['isMalware'] == 0].sample(min_cnt, random_state=123).index) \n",
    "        | set(dataset[dataset['isMalware'] == 1].sample(min_cnt, random_state=123).index)\n",
    "    )\n",
    "].sample(frac=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in tqdm(range(len(fvector_len_cands))):\n",
    "    # feature vector 생성\n",
    "    fvector_len = fvector_len_cands[i]\n",
    "    hasher = FeatureHasher(n_features=fvector_len)\n",
    "    feature_vector = hasher.transform(\n",
    "        [dict(Counter(f)) for f in dataset['basic_blocks_hashed'].tolist()]\n",
    "    ).toarray()\n",
    "\n",
    "    # dataset\n",
    "    x_train, x_test, y_train, y_test = make_dataset_array(\n",
    "        feature_vector,\n",
    "        dataset['isMalware'].values.reshape(-1, 1),\n",
    "    )\n",
    "    \n",
    "    ###########\n",
    "    # for DNN #\n",
    "    ###########\n",
    "    if model_type == 0:\n",
    "        model = make_model_dnn(input_shape=(fvector_len, ))\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2, \n",
    "            verbose=0,\n",
    "        )\n",
    "        evaluate = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    ###########\n",
    "    # for CNN #\n",
    "    ###########\n",
    "    elif model_type == 1:\n",
    "        x_train = x_train.reshape((len(x_train), -1, 1))\n",
    "        x_test = x_test.reshape((len(x_test), -1, 1))\n",
    "        \n",
    "        model = make_model_cnn(input_shape=(fvector_len, 1))\n",
    "        history = model.fit(\n",
    "            x_train, y_train,\n",
    "            epochs=100,\n",
    "            batch_size=batch_size,\n",
    "            validation_split=0.2, \n",
    "            verbose=0,\n",
    "        )\n",
    "        evaluate = model.evaluate(x_test, y_test)\n",
    "    \n",
    "    #####################\n",
    "    # for Random Forest #\n",
    "    #####################\n",
    "    elif model_type == 2:\n",
    "        y_train = y_train.flatten()\n",
    "        y_test = y_test.flatten()\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=120)\n",
    "        model.fit(x_train, y_train)\n",
    "        evaluate = [0, f1_score(y_test, model.predict(x_test)), model.score(x_test, y_test)]\n",
    "\n",
    "    result.append(evaluate)\n",
    "\n",
    "    print(\n",
    "    f\"\"\"\n",
    "    length of feature vector: {fvector_len}\n",
    "        - loss: {evaluate[0]}\n",
    "        - f1-score: {evaluate[1]}\n",
    "        - accuracy: {evaluate[2]}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "result = np.array(result, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 그래프 확인\n",
    "print(\"|\".join(map(str, fvector_len_cands)) + \"|\")\n",
    "print(\"|\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 0].tolist()]) + \"|\") # loss\n",
    "print(\"|\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 2].tolist()]) + \"|\") # accuracy\n",
    "print(\"|\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 1].tolist()]) + \"|\") # f1\n",
    "\n",
    "print(\"\\t\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 0].tolist()]))\n",
    "print(\"\\t\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 2].tolist()]))\n",
    "print(\"\\t\".join([(str(round(i, 4)) + (\"0\" * (6-len(str(round(i, 4)))))) for i in result[:, 1].tolist()]))\n",
    "\n",
    "plt.figure(figsize=(40, 9))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(range(len(fvector_len_cands)), result[:, 0], label='loss')\n",
    "plt.xticks(range(len(fvector_len_cands)), list(map(str, fvector_len_cands)))\n",
    "plt.xlabel(\"Change of Loss\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(range(len(fvector_len_cands)), result[:, 1], label='f1 score')\n",
    "plt.xticks(range(len(fvector_len_cands)), list(map(str, fvector_len_cands)))\n",
    "plt.xlabel(\"Change of F1 score\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(range(len(fvector_len_cands)), result[:, 2], label='accuracy')\n",
    "plt.xticks(range(len(fvector_len_cands)), list(map(str, fvector_len_cands)))\n",
    "plt.xlabel(\"Change of Accuracy\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(f\"{MAIN_DIR}/img/compare_fvector_len_\" + (\"dnn\" if is_dnn else \"cnn\") + \".png\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1ab7052071ffc793c946a28af22b496b4d14622911b9f63699e282abcd3deeb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('malware-detection')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
