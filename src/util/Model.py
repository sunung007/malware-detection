##########
# Import #
##########
import os
import sys
import joblib
import argparse

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm

from keras import regularizers
from keras.models import Sequential, load_model
from keras.layers import (
    Dense,
    Input,
    Conv1D,
    MaxPooling1D,
    Dropout,
    Flatten,
    Activation,
    BatchNormalization,
)
from keras.callbacks import EarlyStopping, Callback, ModelCheckpoint
from keras.optimizers import adam_v2
from keras.regularizers import L2
from keras import backend as K

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import jaccard_score, f1_score, log_loss
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.feature_extraction import FeatureHasher

###############
# Import Util #
###############
sys.path.insert(0, "./../")
from util import *


class Model:
    def __init__(self, name: str, make_model: function) -> None:
        self.name = name
        self.make_model = make_model

    def fit(
        self,
        input_shape: tuple,
        x_train: np.ndarray,
        x_test: np.ndarray,
        y_train: np.ndarray,
        y_test: np.ndarray,
        epochs: int = 100,
        use_fold: bool = True,
        fold_num: int = 5,
        fold_epochs: int = 100,
        batch_size: int = None,
    ):
        """
        Train a model and returns train history.

        Params
        ------
        - x_train(np.ndarray): train dataset. Validation set will be made from this dataset.
        - x_test(np.ndarray): test dataset.
        - y_train(np.ndarray): labels of train dataset.
        - y_test(np.ndarray): labels of test dataset.
        - epochs(int): number of train iterations. (Default: 100)
        - use_fold(bool): Weather using k-fold techniques in training. If this value is False, fold_num and fold_epochs are meaningless. (Default: True)
        - fold_num(int): value of k in k-fold. This value is essential for k-fold. (Default: 5)
        - fold_epochs(int): number of train iterations in each fold. (Default: 100)
        - batch_size(int): Batch size. If this value is None, batch and batch normalization technique are not used in the model. (Default: None)
        """

        print(
            f"""
Shape of input data
    - train : {x_train.shape}
    - test : {x_test.shape}
    ------------------------
    - input shape : {input_shape}
"""
        )

        if use_fold and fold_num == 0:
            print("Input valid 'fold_num' : value of k in k-fold", file=sys.stderr)
            exit(0)

        fold_num = min(fold_num, len(x_train)) if len(x_train) < 10000 else 0
        checkpoint = ModelCheckpoint(
            f"{MAIN_DIR}/model/{self.name}"
            + (".kfold" if fold_num > 0 else "")
            + ".model",
            monitor="custom_f1",
            verbose=0,
            save_best_only=True,
            save_weight_only=True,
            mode="max",
        )

        ##########
        # K-fold #
        ##########

        if fold_num > 0:
            kfold = StratifiedKFold(n_splits=fold_num, shuffle=True)
            kfold_models = []
            kfold_accuracy = []

            for learning_iter, data in enumerate(kfold.split(x_train, y_train)):
                ############
                # training #
                ############

                train_index, valid_index = data
                x_train_fold = x_train[train_index]
                y_train_fold = y_train[train_index]
                x_test_fold = x_train[valid_index]
                y_test_fold = y_train[valid_index]

                # 모델 구성 & 훈련
                model = self.make_model(
                    input_shape=input_shape, use_batch=(batch_size is not None)
                )
                history = model.fit(
                    x_train_fold,
                    y_train_fold,
                    epochs=fold_epochs,
                    batch_size=batch_size,
                    validation_split=0.2,
                    verbose=0,
                    callbacks=[checkpoint],
                )
                model = load_model(
                    f"{MAIN_DIR}/model/{self.name}.kfold.model",
                    custom_objects={"custom_f1": custom_f1},
                )
                kfold_models.append(model)

                ##########
                # result #
                ##########
                evaluate = model.evaluate(x_test_fold, y_test_fold)
                kfold_accuracy.append(
                    evaluate
                )  # test loss, test f1 score, test accuracy

                print(
                    f"""
            Learning Iteration : %d
                - Loss of test fold\t %.8f
                - Accuracy of test fold\t %3.8f
                - F1 score of test fold\t %3.8f
            """
                    % (learning_iter + 1, evaluate[0], evaluate[2], evaluate[1])
                )

                predict = model.predict(x_test_fold)
                test_result = [(y_test_fold.flatten() > 0.5).sum(), len(x_test_fold)]
                test_result[1] -= test_result[0]
                predict_result = [(predict.flatten() > 0.5).sum(), len(x_test_fold)]
                predict_result[1] -= predict_result[0]

                # graph
                plt.figure(figsize=(40, 4))

                plt.subplot(1, 6, 1)
                plt.bar([0, 1], test_result, alpha=0.5, color="red", label="real")
                plt.bar(
                    [0, 1], predict_result, alpha=0.5, color="blue", label="predict"
                )
                plt.legend()

                plt.subplot(1, 6, 2)
                plt.bar([0, 1], test_result, alpha=0.5, color="red", label="real")
                plt.legend()

                plt.subplot(1, 6, 3)
                plt.bar(
                    [0, 1], predict_result, alpha=0.5, color="blue", label="predict"
                )
                plt.legend()

                plt.subplot(1, 6, 4)
                plt.plot(
                    range(len(history.history["loss"])),
                    history.history["loss"],
                    label="loss",
                )
                plt.plot(
                    range(len(history.history["val_loss"])),
                    history.history["val_loss"],
                    label="val_loss",
                )
                plt.axhline(y=evaluate[0], label="loss of test")
                plt.xlabel("Change of Loss")
                plt.legend()

                plt.subplot(1, 6, 5)
                plt.plot(
                    range(len(history.history["binary_accuracy"])),
                    history.history["binary_accuracy"],
                    label="accuracy for train",
                )
                plt.plot(
                    range(len(history.history["val_binary_accuracy"])),
                    history.history["val_binary_accuracy"],
                    label="accuracy for validation",
                )
                plt.axhline(y=evaluate[2], label="accuracy of test")
                plt.xlabel("Change of Accuracy")
                plt.legend()

                plt.subplot(1, 6, 6)
                plt.plot(
                    range(len(history.history["custom_f1"])),
                    history.history["custom_f1"],
                    label="f1 score for train",
                )
                plt.plot(
                    range(len(history.history["val_custom_f1"])),
                    history.history["val_custom_f1"],
                    label="f1 score for validation",
                )
                plt.axhline(y=evaluate[1], label="f1 score of test")
                plt.xlabel("Change of F1 score")
                plt.legend()

                plt.show()

            ###############
            # Final train #
            ###############

            # pick best model
            kfold_accuracy = np.array(kfold_accuracy)
            model = kfold_models[np.argmax(kfold_accuracy[:, 1])]  # f1 score 기준

            # final training
            history = model.fit(
                x_train,
                y_train,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=0.2,
                verbose=0,
                callbacks=[checkpoint],
            )
            model = load_model(
                f"{MAIN_DIR}/model/{self.name}.kfold.model",
                custom_objects={"custom_f1": custom_f1},
            )

            # 결과 확인
            evaluate = model.evaluate(x_test, y_test)
            print(
                f"""
        K-Fold Result
            - batch size : {batch_size}
            - Average loss : %3.8f
            - Average f1 score : %3.8f
            - Average accuracy : %3.8f
            - Final test loss : %3.8f
            - Final test f1 score : %3.8f
            - Final test accuracy : %3.8f
        """
                % (
                    kfold_accuracy[:, 0].mean(),
                    kfold_accuracy[:, 1].mean(),
                    kfold_accuracy[:, 2].mean(),
                    evaluate[0],
                    evaluate[1],
                    evaluate[2],
                )
            )

            plt.figure(figsize=(20, 9))
            plt.plot(kfold_accuracy[:, 0], label="Loss")
            plt.plot(kfold_accuracy[:, 1], label="F1 score")
            plt.plot(kfold_accuracy[:, 2], label="Accuracy")
            plt.axhline(y=kfold_accuracy[:, 0].mean(), label="Averaged loss")
            plt.axhline(y=kfold_accuracy[:, 1].mean(), label="Averaged f1 score")
            plt.axhline(y=kfold_accuracy[:, 2].mean(), label="Averaged accuracy")
            plt.axhline(y=evaluate[0], label="Final loss of train")
            plt.axhline(y=evaluate[1], label="Final f1 score of train")
            plt.axhline(y=evaluate[2], label="Final accuracy of train")
            plt.xlabel("Accuracy according to iters")
            plt.legend()
            plt.show()

        ##############
        # Not K-fold #
        ##############
        else:
            # 모델 구성 & 훈련
            model = self.make_model(input_shape=input_shape)
            history = model.fit(
                x_train,
                y_train,
                batch_size=batch_size,
                epochs=epochs,
                validation_split=0.2,
                verbose=0,
                callbacks=[checkpoint],
            )
            model = load_model(
                f"{MAIN_DIR}/model/{self.name}.model",
                custom_objects={"custom_f1": custom_f1},
            )

        show_result(
            model,
            history,
            x_test=x_test.reshape((len(x_test),) + input_shape),
            y_test=y_test,
        )

        self.model = model
        return history

    def evaluate(self, x_test, y_test):
        return self.model.evaluate(x_test, y_test)


def custom_f1(y_true, y_pred):
    # 출처 : https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras

    def recall_m(y_true, y_pred):
        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))

        recall = TP / (Positives + K.epsilon())
        return recall

    def precision_m(y_true, y_pred):
        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))

        precision = TP / (Pred_Positives + K.epsilon())
        return precision

    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)

    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))


def make_model_cnn(input_shape, use_batch: bool = False):
    model = Sequential()

    conv_units = [2, 4]
    fc_units = [4098, 256, 128, 64]

    # Convolution
    for i in range(len(conv_units)):
        if i == 0:
            model.add(
                Conv1D(
                    3,
                    conv_units[i],
                    kernel_initializer="he_normal",
                    input_shape=input_shape,
                )
            )
        else:
            model.add(Conv1D(3, conv_units[i], kernel_initializer="he_normal"))
        if use_batch:
            model.add(BatchNormalization())
        model.add(Activation("leaky_relu"))
        model.add(Dropout(0.2))
        model.add(MaxPooling1D(2))

    model.add(Flatten())

    for i in range(len(fc_units)):
        if i == 0:
            model.add(
                Dense(
                    units=fc_units[i],
                    kernel_initializer="he_normal",
                    input_shape=input_shape,
                )
            )
        else:
            model.add(Dense(units=fc_units[i], kernel_initializer="he_normal"))
        if use_batch:
            model.add(BatchNormalization())
        model.add(Activation("leaky_relu"))

        if i < len(fc_units) - 3:
            model.add(Dropout(0.2))

    model.add(Dense(units=1, kernel_initializer="he_normal", activation="sigmoid"))
    model.compile(
        loss="binary_crossentropy",
        optimizer=adam_v2.Adam(0.0001),
        metrics=[custom_f1, "binary_accuracy"],
    )

    return model


def make_model_dnn(input_shape, use_batch=False):
    units = [4096, 2048, 512, 128]

    model = Sequential()
    for i in range(len(units)):
        # linear
        if i == 0:
            model.add(
                Dense(
                    units=units[i],
                    kernel_initializer="he_normal",
                    # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                    # bias_regularizer=regularizers.L2(1e-4),
                    # activity_regularizer=regularizers.L2(1e-5),
                    input_shape=input_shape,
                )
            )
        else:
            model.add(
                Dense(
                    units=units[i],
                    kernel_initializer="he_normal",
                    # kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                    # bias_regularizer=regularizers.L2(1e-4),
                    # activity_regularizer=regularizers.L2(1e-5)
                )
            )
        # batch normlization
        if use_batch:
            model.add(BatchNormalization())
        # activation
        model.add(Activation("leaky_relu"))
        # dropout
        if i < len(units) - 5:
            model.add(Dropout(0.4))
        elif i < len(units) - 3:
            model.add(Dropout(0.2))

    model.add(Dense(units=1, kernel_initializer="he_normal", activation="sigmoid"))
    model.compile(
        loss="binary_crossentropy",
        optimizer=adam_v2.Adam(0.0001),
        metrics=[custom_f1, "binary_accuracy"],
    )

    return model


def show_result(model, history, x_test, y_test):
    loss, f1, acc = model.evaluate(x_test, y_test)

    print(
        f"""
    Result
        - Loss : %3.8f
        - Accuracy : %3.8f
        - F1 score : %3.8f
    """
        % (loss, acc, f1)
    )

    plt.figure(figsize=(30, 9))
    plt.subplot(1, 3, 1)
    plt.plot(range(len(history.history["loss"])), history.history["loss"], label="loss")
    plt.plot(
        range(len(history.history["val_loss"])),
        history.history["val_loss"],
        label="val_loss",
    )
    plt.axhline(loss, color="red", label="loss of testset")
    plt.xlabel("Change of Loss")
    plt.legend()

    plt.subplot(1, 3, 2)
    plt.plot(
        range(len(history.history["binary_accuracy"])),
        history.history["binary_accuracy"],
        label="accuracy for training",
    )
    plt.plot(
        range(len(history.history["val_binary_accuracy"])),
        history.history["val_binary_accuracy"],
        label="accuracy for validation",
    )
    plt.axhline(acc, color="red", label="accuracy of testset")
    plt.xlabel("Change of Accuracy")
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(
        range(len(history.history["custom_f1"])),
        history.history["custom_f1"],
        label="f1 score for training",
    )
    plt.plot(
        range(len(history.history["val_custom_f1"])),
        history.history["val_custom_f1"],
        label="f1 score for validation",
    )
    plt.axhline(f1, color="red", label="f1 score of testset")
    plt.xlabel("Change of F1 score")
    plt.legend()

    plt.show()
