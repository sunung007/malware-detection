##########
# Import #
##########
import os
import sys

import numpy as np
import pandas as pd

from tqdm import tqdm
from hashlib import sha256
from collections import Counter

from sklearn.feature_extraction import FeatureHasher

###############
# Import Util #
###############
sys.path.insert(0, "./../")
from util import *


class Fvector:
    def __init__(self) -> None:
        """
        make feature vector
        """

        # seperator : jump instructions + return instructions
        jmp_inst = [
            "jmp",
            "jz",
            "jnz",
            "jb",
            "jnb",
            "jl",
            "jle",
            "jg",
            "ja",
            "jbe",
            "jge",
            "jno",
            "jns",
            "js",
            "jp",
            "jnp",
            "jo",
            "jecxz",
            "jcxz",
        ]
        ret_inst = ["retnw", "retfw", "retf", "retfw", "retn", "retnw"]
        self.seperator = jmp_inst + ret_inst

    def split_to_basic_block(
        self, commands: list, min_opcode: int = 10, min_basic_block: int = 100
    ) -> list:
        """
        split sequence of opcode into basic blocks

        params
        ---
        - commands(list) : list of commands.
        - min_opcodes(int) : minimum number of opcodes in a basic block. (Default: 10)
        - min_basic_block(int) : minimum number of basic blocks in a file. (Default : 100)
        return
        ----
        - list: 2d array. Basic blocks in a file
        """

        cur = []
        basic_blocks = []

        for com in commands:
            cur.append(com)
            if com in self.seperator:
                if len(cur) > min_opcode:
                    basic_blocks.append(cur)
                cur = []
        basic_blocks.append(cur)

        return [] if len(basic_blocks) < min_basic_block else basic_blocks

    def make_hashset(self, blocks: list) -> list:
        """
        make the basic blocks list of hashed string.
        For hashing, use sha256

        param
        ----
        - blocks(list, 2d-list) : sequence of basic blocks

        return
        -----
        - list : sequence of hashed values

        Example
        ----
        basic blocks : [[mov, mov, ..., jmp], ..., [add, mov, ..., ret]]
        -> link to one string : [movmov...jmp, ..., addmov...ret]
        -> hashing(return) : [xxxxxx, ..., xxxxx]

        """

        return (
            [sha256(("".join(block)).encode()).hexdigest() for block in blocks]
            if len(blocks) > 0
            else []
        )

    def feature_hashing(
        self, df: pd.DataFrame, col_name: str, features: int = 32
    ) -> pd.DataFrame:
        """
        make feature vector

        params
        ----
        - df(pd.DataFrame) : file.
        - col_name(str) : name of hashset column in dataframe.
        - features(int) : length of feature vector.
        """

        # feature vector
        hasher = FeatureHasher(n_features=features)
        feature_vector = hasher.transform(
            [dict(Counter(f)) for f in df[col_name].tolist()]
        ).toarray()

        # insert into dataframe
        df = pd.concat(
            [
                df,
                pd.DataFrame(
                    feature_vector,
                    columns=[f"feature_vector_{i}" for i in range(1, features + 1)],
                ),
            ],
            axis=1,
        )

        return df

    def adjust_proportion(
        self, df: pd.DataFrame, target_col: str = "isMalware"
    ) -> pd.DataFrame:
        # 정상/악성 비율 맞추기
        min_cnt = min(len(df[df[target_col] == 0]), len(df[df[target_col] == 1]))
        parsed = df.loc[
            (
                set(df[df[target_col] == 0].sample(min_cnt, random_state=123).index)
                | set(df[df[target_col] == 1].sample(min_cnt, random_state=123).index)
            )
        ].sample(frac=1.0)

        print(
            f"""
    전체 파일 수 : {len(df)}
    -------------------------------
    정상 파일 수 : {len(df[df[target_col] == 0])}
    악성 파일 수 : {len(df[df[target_col] == 1])}
    -------------------------------
    파징 후 파일 수 : {len(parsed)}
        """
        )

        return parsed

    def fit(
        self,
        df: pd.DataFrame,
        features: int = 32,
        label_cname: str = "isMalware",
        opcode_cname: str = "opcodes",
        return_original: bool = False,
    ) -> pd.DataFrame:
        """
        make feature vector

        params
        ----
        - df(pd.DataFrame) : file
        - features(int) : length of feature vector
        - label_cname(str): label column name
        - opcode_cname(str): opcodes column name

        return
        ----
        - pd.DataFrame : dataframe including feature vector
        """

        df = df.copy()

        # split opcode sequence into basic blocks
        tqdm.pandas(desc="spliting")
        df["basic_blocks"] = df[opcode_cname].progress_apply(
            lambda l: self.split_to_basic_block(l)
        )
        df["basic_blocks_num"] = df["basic_blocks"].apply(lambda l: len(l))

        # drop files which do not have any basic block
        print(
            "Num of files which have no basic blocks:",
            len(df[df["basic_blocks_num"] == 0].index),
        )
        df.drop(df[df["basic_blocks_num"] == 0].index, inplace=True)
        df.reset_index(drop=True, inplace=True)

        # make hashset
        tqdm.pandas(desc="hashing")
        df["basic_blocks_hashed"] = df["basic_blocks"].progress_apply(self.make_hashset)

        # make feature vector
        df = self.feature_hashing(df, "basic_blocks_hashed", features)

        # proportion
        parsed = self.adjust_proportion(df, label_cname)

        if return_original:
            return df, parsed
        else:
            return parsed
