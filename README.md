# Maleware Detection using Opcode Sequence

## Todo List

- [ ] CNN 모델링 -> CNN vs DNN 결정
- [ ] feature vector length에 따른 정확도 확인
  - -> 가능하면 CNN, DNN 각각에 대한 정확도 변화율 확인
- [ ] v-gram 사용 시 정확도 확인
  - -> 사실상 불가능 할 것 같다.

---

#### Summary

[V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지](#reference) 논문 리뷰 및 구현

#### Member

| 구분   | 이름   | 소속                            | 이메일                  |
| ------ | ------ | ------------------------------- | ----------------------- |
| 팀원 1 | 김선웅 | 한양대학교 컴퓨터소프트웨어학부 | sunung007@hanyang.ac.kr |
| 팀원 2 | 김성애 | 한양대학교 컴퓨터소프트웨어학부 |                         |

---

## Contents

- [Usage](#usage)
- [Implements](#implements)
- [Result](#result)
- [Reference](#reference)

---

## Usage

1. 필요한 라이브러리 설치

   - 명령어 : `pip install -r requirements.txt`

<!-- 2. ~~데이터 다운로드(테스트 중에는 생략)~~
   - 명령어 : `python3 src/util/download_dataset.py` -->

2. 코드 실행
   - 파일명 : `src/main.ipynb`
   - 실행 순서 : '파일 읽기' 전까지의 블락 -> 'Classifier' 이후의 블락
   - 주의 : Classifier 이후의 블락 중 `fdataset = pd.read_csv(f"{MAIN_DIR}/data/traindata_only_fvector_size={FEATURE_VECTOR_LEN}.csv", header=0)` 코드가 주석처리 되어있을 경우 해제해야 한다.

---

## Implements

#### Environment

| 구분            | 내용                                            |
| --------------- | ----------------------------------------------- |
| OS              | Ubuntu 20.04.4 LTS                              |
| CPU             | 11th Gen Intel(R) Core(TM) i9-11900KF @ 3.50GHz |
| GPU             | NVIDIA Corporation Device 2204 (rev a1)         |
| Python          | 3.8.10                                          |
| Major Libraries | tensorflow                                      |
|                 | keras                                           |
|                 | sklearn                                         |
|                 | pandas                                          |
|                 | numpy                                           |
|                 | matplotlib                                      |

### Making Dataset

데이터셋을 구성하는 과정은 다음과 같다.

1. Basic block 구성
   - Jump와 return opcodes를 기준으로 opcode sequence를 basic block의 sequence로 나눈다.
   - 하나의 파일은 basic block의 sequence로 이루어지며, 각 basic block은 opcode의 sequence로 이루어진다.
   - 단, basic block 내의 opcode의 수가 10개 미만이거나 파일 내의 basic block 수가 100개 미만인 경우 outlier로 간주하고 제거한다.
2. Hash Basic block
   - 각 basic block의 opcode sequence를 이어붙여서 하나의 string으로 만들고, 만들어진 string에 대해 hashing을 수행한다.
   - 하나의 파일은 hashed string의 sequence로 이루어진다.
   - Hashing에는 sha256 알고리즘을 이용하였다.
3. Feature vector 생성
   - Feature hashing 알고리즘을 이용하여 hashed string sequence를 일정 길이의 feature vector로 변환한다.
   - 하나의 파일은 하나의 feature vector로 이루어진다.

### Training

적은 데이터셋에서 높은 정확도를 이끌어내기 위해 훈련 시 k-fold cross validation 방법을 이용하였다.

DNN과 CNN 모델을 구성하고 각 모델에 대한 정확도를 비교하였다.

#### DNN

- fvector length : 32
  - Average accuracy : 76.32360101 %
  - Final test accuracy : 78.14113498 %
- fvector length : 1024
  - batch : None
    - Average accuracy : 83.85687709 %
    - Final test accuracy : 85.19793749 %
  - batch : 256
    - Average accuracy : 86.31090164 %
    - Final test accuracy : 83.47676396 %
  - batch size : 256
    - Average accuracy : 85.36383152 %
    - Final test accuracy : 84.85370278 %
  - batch size : 512
    - Average accuracy : 86.09714508 %
    - Final test accuracy : 86.40275598 %
    - Average accuracy : 84.54607010 %
    - Final test accuracy : 87.09121943 %
    - Average accuracy : 85.45013070 %
    - Final test accuracy : 84.33734775 %
- fvector length : 2048
  - batch size : 256
    - Average accuracy : 85.70856452 %
    - Final test accuracy : 86.57487035 %
  - batch size : 512
    - Average accuracy : 85.92482448 %
    - Final test accuracy : 88.12392354 %
    - Average accuracy : 86.09593987 %
    - Final test accuracy : 86.40275598 %
    - Average accuracy : 86.26891017 %
    - Final test accuracy : 86.05852127 %
    - Average accuracy : 86.13857985 %
    - Final test accuracy : 88.12392354 %
    - Average accuracy : 86.13857985 %
    - Final test accuracy : 85.88640094 %
    - Average accuracy : 86.35400295 %
    - Final test accuracy : 87.09121943 %
    - Average accuracy : 86.74249172 %
    - Final test accuracy : 87.60757446 %

#### CNN

- fvector length : 32
  - Batch : None
    - Average accuracy : 76.53809786 %
    - Final test accuracy : 74.87091422 %
  - Batch : 64
    - Average accuracy : 74.25927043 %
    - Final test accuracy : 72.97762632 %
  - Batch : 128
    - Average accuracy : 77.83101559 %
    - Final test accuracy : 79.00171876 %
  - Batch : 256
    - 3 conv + 5 fc (not included output)
      - Average accuracy : 78.34501266 %
      - Final test accuracy : 78.14113498 %
    - 2 conv + 5 fc
      - Average accuracy : 80.02669692 %
      - Final test accuracy : 79.86230850 %
    - 2 conv + 4 fc
      - Average accuracy : 79.98164654 %
      - Final test accuracy : 79.34595346 %
      - Average accuracy : 78.86466384 %
      - Final test accuracy : 80.03442287 %
  - Batch : 512
    - Average accuracy : 77.74341822 %
    - Final test accuracy : 79.69018817 %
- fvector length : 1024
  - Average accuracy : 73.26779604 %
  - Final test accuracy : 78.48536968 %
  - Average accuracy : 75.11948466 %
  - Final test accuracy : 80.03442287 %
  - Average accuracy : 79.89655256 %
  - Final test accuracy : 79.17383909 %
- fvector length : 2048
  - Batch : 256
    - Average accuracy : 80.67111611 %
    - Final test accuracy : 85.37005186 %
  - Batch : 512
    - Average accuracy : 82.09315896 %
    - Final test accuracy : 85.19793749 %

#### Random Forest

- fvector length : 1024
  - 0.8795180722891566 (n = 183)
- fvector length : 2048
  - 0.8967297762478486 (n = 222)
  - 0.8950086058519794 (n = 282)

#### LGBM

500 : 0.87263339
450 : 0.87263339

#### XGB

0.84

---

## Experiment

### Outlier 처리/미처리 (in DNN)

Outlier의 처리 조건은 다음과 같다.

- Basic block 내의 opcode의 수가 n개 이하인 block은 버린다.
- File 내의 basic block 수가 m개 이하인 block은 버린다.

| 구분           | Loss       | Accuracy     | 비고            |
| -------------- | ---------- | ------------ | --------------- |
| Outlier 미처리 | 3.53744268 | 56.67475462% |                 |
| Outlier 처리   | 1.71627963 | 80.37865758% | n = 10, m = 100 |

> Outlier 미처리 시 결과 (좌 : loss 변화 / 우 : accuracy 변화)

<img src="img/result_dnn_not_process_outlier.png"/>

> Outlier 처리 시 결과 (좌 : loss 변화 / 우 : accuracy 변화)

<img src="img/result_dnn_process_outlier(n=10, m=100).png"/>

### Feature Vector 길이에 따른 변화 (DNN vs CNN)

| Model         | Measure  | 32     | 64     | 128    | 256    | 512    | 1024   | 2048   | 4096   | 8192   |
| ------------- | -------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
| DNN           | Loss     | 0.9465 | 1.0090 | 1.0593 | 1.8251 | 1.7815 | 1.4133 | 2.3910 | 1.3292 | 2.6064 |
|               | Accuracy | 0.8222 | 0.8402 | 0.8544 | 0.8505 | 0.8647 | 0.8582 | 0.8595 | 0.8724 | 0.8711 |
|               | F1-scroe | 0.8513 | 0.8709 | 0.8842 | 0.8758 | 0.8938 | 0.8863 | 0.8845 | 0.9003 | 0.9005 |
| CNN           | Loss     | 0.6433 | 0.5028 | 1.7610 | 0.6391 | 0.3932 | 0.7011 | 0.7636 | 0.5723 | 0.8209 |
|               | Accuracy | 0.7126 | 0.7320 | 0.7358 | 0.7784 | 0.8351 | 0.8454 | 0.8698 | 0.8595 | 0.8582 |
|               | F1-score | 0.7463 | 0.7998 | 0.8227 | 0.8404 | 0.8701 | 0.8791 | 0.8967 | 0.8834 | 0.8868 |
| Random Forest | Loss     | -      | -      | -      | -      | -      | -      | -      | -      | -      |
|               | Accuracy | 0.8389 | 0.8441 | 0.8582 | 0.8698 | 0.8763 | 0.8840 | 0.8879 | 0.9046 | 0.8905 |
|               | F1-score | 0.8746 | 0.8781 | 0.8875 | 0.8968 | 0.9004 | 0.9076 | 0.9089 | 0.9219 | 0.9104 |

> DNN의 변화 : 정확도는 2048 -> 256 -> 512 -> ... 순으로 높지만, loss 대비 정확도는 256이 제일 낫다.

<img src="img/compare_fvector_len_dnn.png"/>

---

## Result

---

## Reference

- 정성민, 김현석, 김영재 and 윤명근. "V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지" 정보과학회논문지 46, no.7 (2019) : 599-605.doi: https://doi.org/10.5626/JOK.2019.46.7.599

### Dataset

- 정상/악성파일 opcodes : 정보보호 R&D 데이터챌린지 2017(http://datachallenge.kr), 한국인터넷진흥원(KISA), https://drive.google.com/file/d/1to0x585_GdG_KtNCbNroNE_w-IEYZHOh/view?usp=sharing

- kaggle : `kaggle competitions download -c malware-classification`
