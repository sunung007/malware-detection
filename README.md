# Maleware Detection using Opcode Sequence

#### Summary

[V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지](#reference) 논문 리뷰 및 구현

#### Member

|  구분  |  이름  | 소속                            | 이메일                   |
| :----: | :----: | :------------------------------ | :----------------------- |
| 팀원 1 | 김선웅 | 한양대학교 컴퓨터소프트웨어학부 | sunung007@hanyang.ac.kr  |
| 팀원 2 | 김성애 | 한양대학교 컴퓨터소프트웨어학부 | abc4571998@hanyang.ac.kr |

---

## Contents

- [Usage](#usage)
- [Implements](#implements)
- [Result](#result)
- [Reference](#reference)

---

## Usage

#### 공통

- 기본 정보 수정 : `src/util/info.py` 안의 내용을 각 환경에 맞게 수정
- 라이브러리 설치 : `pip install -r requirements.txt`
- 데이터셋이 있는 경우 : `data/` 디렉터리 안에 `total_data`의 이름으로 저장

#### 악성코드 분류

1. 모델 학습
   - 명령어 : `python3 src/train.py --fvlen={feature_vector_length} --compare_fvlen=False --model={model_type}`
     - feature_vector_length : feature vector 길이
     - model : 사용할 모델 종류 (all, dnn, cnn, rf)
       - all : 모든 모델에 대해 학습 진행
       - dnn : DNN 모델 이용
       - cnn : CNN 모델 이용
       - rf : Random forest 이용
2. \*.exe 파일 분류
   - 명령어 : `python3 src/usage.py --exe={exe_file_path}`
     - exe_file_path : 분류할 exe file의 경로

#### Feature vector 길이에 따른 정확도 비교

- 명령어 : `python3 src/train.py --compare_fvlen=True`

---

## Implements

`src/util/Model/custom_f1` function의 출처는 "https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras" 입니다.
그 외의 모든 코드는 직접 구현하였습니다.

#### Environment

| 구분            | 내용                                            |
| :-------------- | :---------------------------------------------- |
| OS              | Ubuntu 20.04.4 LTS                              |
| CPU             | 11th Gen Intel(R) Core(TM) i9-11900KF @ 3.50GHz |
| GPU             | NVIDIA Corporation Device 2204 (rev a1)         |
| Python          | 3.8.10                                          |
| Major Libraries | tensorflow==2.8.0                               |
|                 | keras==2.8.0                                    |
|                 | sklearn==0.0                                    |
|                 | pandas==1.4.2                                   |
|                 | numpy==1.22.3                                   |
|                 | pefile==2022.5.30 // For disassembling          |
|                 | capstone==4.0.2 // For disassembling            |

#### Flow

전반적인 과정은 다음과 같다.

1. exe 파일에서 opcode 추출
2. Feature vector 생성
   1. Opcode sequence를 basic block의 sequence로 split
   2. 각 basic block을 하나의 string으로 연결
   3. SHA256 알고리즘을 이용하여 각 basic block string을 hashing
   4. Feature hashing
3. 이진 분류 모델을 이용하여 악성코드 분류

<img src="./img/overall_process.jpeg">

### Making Dataset

데이터셋을 구성하는 과정은 다음과 같다.

1. Basic block 구성
   - Jump와 return opcodes를 기준으로 opcode sequence를 basic block의 sequence로 나눈다.
   - 하나의 파일은 basic block의 sequence로 이루어지며, 각 basic block은 opcode의 sequence로 이루어진다.
   - 단, basic block 내의 opcode의 수가 10개 미만이거나 파일 내의 basic block 수가 100개 미만인 경우 outlier로 간주하고 제거한다.
2. Hash Basic block
   - 각 basic block의 opcode sequence를 이어붙여서 하나의 string으로 만들고, 만들어진 string에 대해 hashing을 수행한다.
   - 하나의 파일은 hashed string의 sequence로 이루어진다.
   - Hashing에는 sha256 알고리즘을 이용하였다.
3. Feature vector 생성
   - Feature hashing 알고리즘을 이용하여 hashed string sequence를 일정 길이의 feature vector로 변환한다.
   - 하나의 파일은 하나의 feature vector로 이루어진다.

### Training

적은 데이터셋에서 높은 정확도를 이끌어내기 위해 훈련 시 k-fold cross validation 방법을 이용하였다.

#### Outlier 처리/미처리 (in DNN)

| 구분           | Loss       | Accuracy     | 비고            |
| :------------- | :--------- | :----------- | :-------------- |
| Outlier 미처리 | 3.53744268 | 56.67475462% |                 |
| Outlier 처리   | 1.71627963 | 80.37865758% | n = 10, m = 100 |

> Outlier 미처리 시 결과 (좌 : loss 변화 / 우 : accuracy 변화)

<img src="img/result_dnn_not_process_outlier.png"/>

> Outlier 처리 시 결과 (좌 : loss 변화 / 우 : accuracy 변화)

<img src="img/result_dnn_process_outlier(n=10, m=100).png"/>

#### Feature Vector 길이에 따른 변화

|     Model     | Measure  |   32   |   64   |  128   |  256   |  512   |  1024  |  2048  |  4096  |  8192  | 16394  | 32768  |
| :-----------: | :------- | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
|      DNN      | Loss     | 0.9465 | 1.0090 | 1.0593 | 1.8251 | 1.7815 | 1.4133 | 2.3910 | 1.3292 | 2.6064 | 0.9507 | 0.6919 |
|               | Accuracy | 0.8222 | 0.8402 | 0.8544 | 0.8505 | 0.8647 | 0.8582 | 0.8595 | 0.8766 | 0.8805 | 0.8662 | 0.8724 |
|               | F1-scroe | 0.8513 | 0.8709 | 0.8842 | 0.8758 | 0.8938 | 0.8863 | 0.8845 | 0.9003 | 0.9099 | 0.8987 | 0.8939 |
|      CNN      | Loss     | 0.6433 | 0.5028 | 1.7610 | 0.6391 | 0.3932 | 0.7011 | 0.7636 | 0.5723 | 0.8209 | 1.4597 | 1.3207 |
|               | Accuracy | 0.7126 | 0.7320 | 0.7358 | 0.7784 | 0.8351 | 0.8454 | 0.8698 | 0.8595 | 0.8582 | 0.8399 | 0.8330 |
|               | F1-score | 0.7463 | 0.7998 | 0.8227 | 0.8404 | 0.8701 | 0.8791 | 0.8967 | 0.8834 | 0.8868 | 0.8288 | 0.8188 |
| Random Forest | Loss     |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |
|               | Accuracy | 0.8389 | 0.8441 | 0.8582 | 0.8698 | 0.8763 | 0.8840 | 0.8879 | 0.9046 | 0.8905 | 0.9019 | 0.8830 |
|               | F1-score | 0.8746 | 0.8781 | 0.8875 | 0.8968 | 0.9004 | 0.9076 | 0.9089 | 0.9219 | 0.9104 | 0.9022 | 0.8855 |

<img src="img/compare_fvector_len.png"/>

---

## Reference

- 정보보호 R&D 데이터챌린지 2017(http://datachallenge.kr), 한국인터넷진흥원(KISA), https://drive.google.com/file/d/1to0x585_GdG_KtNCbNroNE_w-IEYZHOh/view?usp=sharing
- 정성민, 김현석, 김영재 and 윤명근. "V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지" 정보과학회논문지 46, no.7 (2019) : 599-605.doi: https://doi.org/10.5626/JOK.2019.46.7.599
- "Implementing the Macro F1 Score in Keras: Do’s and Don’ts", Neptune Blog, last modified March 18th. 2022, accessed May 1st. 2022, https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras
