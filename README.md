# Maleware Detection using Opcode Sequence

#### Summary

[V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지](#reference) 논문 리뷰 및 구현

---

## Contents

- [Usage](#usage)
- [Implements](#implements)
- [Result](#result)
- [Reference](#reference)

---

## Usage

#### 공통

- 기본 경로 수정 : `src/util/info.py`의 `MAIN_DIR` 을 프로젝트의 root directory 로 수정
- 라이브러리 설치 : pip install -r requirements.txt
- 데이터셋
  - 출처 : 정보보호 R&D 데이터챌린지 2017, http://datachallenge.kr, 한국인터넷진흥원(KISA)
  - 위치
    - `./data/total_data/0`: benign
    - `./data/total_data/1`: malware

#### 악성코드 분류

1. 모델 학습
   - 명령어 : `python3 src/train.py --fvlen={feature_vector_length} --compare_fvlen=False --model={model_type}`
     - feature_vector_length : feature vector 길이
     - model : 사용할 모델 종류 (all, dnn, cnn, rf)
       - all : 모든 모델에 대해 학습 진행
       - dnn : DNN 모델 이용
       - cnn : CNN 모델 이용
       - rf : Random forest 이용
2. \*.exe 파일 분류
   - 명령어 : `python3 src/usage.py --exe={exe_file_path}`
     - exe_file_path : 분류할 exe file의 경로

#### Feature vector 길이에 따른 정확도 비교

- 명령어 : `python3 src/train.py --compare_fvlen=True`

---

## Implements

`src/util/Model/custom_f1` function의 출처는 "https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras" 입니다.
그 외의 모든 코드는 직접 구현하였습니다.

### Environment

| 구분   | 내용                                            |
| :----- | :---------------------------------------------- |
| OS     | Ubuntu 20.04.4 LTS                              |
| CPU    | 11th Gen Intel(R) Core(TM) i9-11900KF @ 3.50GHz |
| GPU    | NVIDIA Corporation Device 2204 (rev a1)         |
| Python | 3.8.10                                          |

#### 주요 라이브러리

```bash
# Data Processing
numpy==1.22.3
pandas==1.4.2
sklearn==0.0

# Modeling
tensorflow==2.8.0
keras==2.8.0

# Disassembling
pefile==2022.5.30
capstone==4.0.2
```

### Making Feature Vector

Feature vector 의 생성 방법은 아래와 같으며, 코드에서의 flow chart 는 그림 1 과 같습니다. 해당 과정 중 외부에서 가져온 코드는 없습니다.

1. Basic block 구성 : Opcode sequence 를 basic block 의 sequence 로 split 합니다.
   1. Jump 와 return opcodes 를 기준으로 opcode sequence 를 basic block 의 sequence 로 나눕니다.
   2. 하나의 파일은 basic block 의 sequence 로 이루어지며, 각 basic block 은 opcode 의 sequence 로 이루어집니다.
   3. 단, basic block 내의 opcode 의 수가 10 개 미만이거나 파일 내의 basic block 수가 100 개 미만인 경우 outlier 로 간주하고 제거합니다.
2. 각 basic block 을 하나의 string 으로 연결 : 각 basic block 의 opcode sequence 를 이어붙여서 하나의 string 으로 만듭니다. 하나의 파일은 string sequence 로 이루어집니다.
3. SHA256 알고리즘을 이용하여 각 basic block string 을 hashing : 하나의 파일은 hashed string 의 sequence 로 이루어집니다.
4. Feature hashing : Feature hashing 알고리즘을 이용하여 hashed string sequence 를 일정 길이의 feature vector 로 변환합니다. 하나의 파일은 하나의 feature vector 로 이루어집니다.

<center>
<figure>
<img src="img/flow_feature_vector.png" width=180>
<figcaption>[그림 1] Feature Vector 생성 과정</figcaption>
</figure>
</center>

### Modeling and Training

명령어 `python3 src/train.py --compare_fvlen=False --fvlen=4098 --model=all`을 통해 코드를 실행할 수 있습니다. 전반적인 과정은 다음과 같습니다 (그림 2).

1. Feature vector 생성 ([Making Feature Vector 참고](#making-feature-vector))
2. 모델생성및학습
3. 학습된모델저장

DNN 은 dense-dropout 의 4 개 set 을 쌓아서 구성하였고, CNN 은 convolution-max pooling- dropout 의 2 개 set 와 3 개의 dense layer 를 쌓아서 구성하였습니다. Loss function 으로는 binary cross entropy 를 적용하였고 hidden layer 의 activation 은 leaky ReLU 를 적용하였습니다. Binary classification 이기 때문에 마지막 layer 에는 sigmoid 함수를 activation function 으로 사용하였습니다.

학습 속도 개선 및 과적합(overfitting) 방지를 위해 batch normalization, dropout, adam optimizer 등을 활용하였고, 학습에는 적은 데이터셋에서 높은 정확도를 이끌어내기 위해 k-fold cross validation 방법을 이용하였습니다.

<center>
<figure>
<img src="img/flow_modeling.png" width=400>
<figcaption>[그림 2] 모델 학습 과정</figcaption>
</figure>
</center>

### Application

명령어 `python3 src/usage.py --exe={exe_file_path} --fvlen={feature_vector_length} -- capstone={whether_use_capstone_library}`을 통해 실제 exe file을 분류하는 코드를 실행할 수 있습니다. 전반적인 과정은 다음과 같습니다.

1. exe 파일에서 opcode 추출
2. Feature vector 생성 ([Making Feature Vector 참고](#making-feature-vector))
3. 이진 분류 모델을 이용하여 악성코드 분류

<center>
<figure>
<img src="img/flow_application.png" width=400>
<figcaption>[그림 3] Exe file 분류 과정</figcaption>
</figure>
</center>

<center>
<figure>
<img src="img/overall_process.jpeg">
<figcaption>[그림 4] 수행 과정의 전반적 개요</figcaption>
</figure>
</center>

---

## Result

#### Feature Vector 길이에 따른 변화

아래 표는 feature vector 길이가 변함에 따라 각 모델의 loss, 정확도, f1-score 의 변화를 나타낸
것으로, random forest 를 사용했을 때의 정확도가 가장 높음을 확인할 수 있습니다 (그림 5).

|     Model     | Measure  |   32   |   64   |  128   |  256   |  512   |  1024  |  2048  |  4096  |  8192  | 16394  | 32768  |
| :-----------: | :------- | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: | :----: |
|      DNN      | Loss     | 0.9465 | 1.0090 | 1.0593 | 1.8251 | 1.7815 | 1.4133 | 2.3910 | 1.3292 | 2.6064 | 0.9507 | 0.6919 |
|               | Accuracy | 0.8222 | 0.8402 | 0.8544 | 0.8505 | 0.8647 | 0.8582 | 0.8595 | 0.8766 | 0.8805 | 0.8662 | 0.8724 |
|               | F1-scroe | 0.8513 | 0.8709 | 0.8842 | 0.8758 | 0.8938 | 0.8863 | 0.8845 | 0.9003 | 0.9099 | 0.8987 | 0.8939 |
|      CNN      | Loss     | 0.6433 | 0.5028 | 1.7610 | 0.6391 | 0.3932 | 0.7011 | 0.7636 | 0.5723 | 0.8209 | 1.4597 | 1.3207 |
|               | Accuracy | 0.7126 | 0.7320 | 0.7358 | 0.7784 | 0.8351 | 0.8454 | 0.8698 | 0.8595 | 0.8582 | 0.8399 | 0.8330 |
|               | F1-score | 0.7463 | 0.7998 | 0.8227 | 0.8404 | 0.8701 | 0.8791 | 0.8967 | 0.8834 | 0.8868 | 0.8288 | 0.8188 |
| Random Forest | Loss     |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |   -    |
|               | Accuracy | 0.8389 | 0.8441 | 0.8582 | 0.8698 | 0.8763 | 0.8840 | 0.8879 | 0.9046 | 0.8905 | 0.9019 | 0.8830 |
|               | F1-score | 0.8746 | 0.8781 | 0.8875 | 0.8968 | 0.9004 | 0.9076 | 0.9089 | 0.9219 | 0.9104 | 0.9022 | 0.8855 |

<center>
<figure>
<img src="img/compare_fvector_len.png"/>
<figcaption>[그림 5] Feature Vector 길이에 따른 모델별 Loss, Accuracy, F1-Score의 변화 그래프</figcaption>
</figure>
</center>

---

## Team

|  이름  |                  김선웅                   |                   김성애                    |
| :----: | :---------------------------------------: | :-----------------------------------------: |
|  소속  |      한양대학교 컴퓨터소프트웨어학부      |       한양대학교 컴퓨터소프트웨어학부       |
| 이메일 |          sunung007@hanyang.ac.kr          |          abc4571998@hanyang.ac.kr           |
| Github | [sunung007](https://github.com/sunung007) | [abc4571998](https://github.com/abc4571998) |

---

## Reference

- 정보보호 R&D 데이터챌린지 2017(http://datachallenge.kr), 한국인터넷진흥원(KISA), https://drive.google.com/file/d/1to0x585_GdG_KtNCbNroNE_w-IEYZHOh/view?usp=sharing
- 정성민, 김현석, 김영재 and 윤명근. "V-그램: 명령어 기본 블록과 딥러닝 기반의 악성코드 탐지" 정보과학회논문지 46, no.7 (2019) : 599-605.doi: https://doi.org/10.5626/JOK.2019.46.7.599
- "Implementing the Macro F1 Score in Keras: Do’s and Don’ts", Neptune Blog, last modified March 18th. 2022, accessed May 1st. 2022, https://neptune.ai/blog/implementing-the-macro-f1-score-in-keras
